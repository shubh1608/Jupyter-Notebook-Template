{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pacific-maria",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "* Filter method\n",
    "* Wrapper method\n",
    "* Embedded method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-wales",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "favorite-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "import math\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "\n",
    "# using feature engine library\n",
    "from feature_engine.selection import (\n",
    "    DropCorrelatedFeatures, \n",
    "    SmartCorrelatedSelection,\n",
    "    DropConstantFeatures, \n",
    "    DropDuplicateFeatures,\n",
    "    SelectBySingleFeaturePerformance,\n",
    "    SelectByTargetMeanPerformance,\n",
    "    SelectByShuffling,\n",
    "    RecursiveFeatureElimination,\n",
    "    RecursiveFeatureAddition\n",
    ")\n",
    "\n",
    "# to obtain the mutual information values\n",
    "from sklearn.feature_selection import (\n",
    "    f_classif,\n",
    "    f_regression,\n",
    "    mutual_info_classif, \n",
    "    mutual_info_regression,\n",
    "    VarianceThreshold\n",
    ")\n",
    "# to select the features\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "\n",
    "# wrapper methods\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "# embedded methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-statement",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effective-chance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../dataset/Bank_Personal_Loan_Modelling_transformed.xlsx')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "devoted-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "target='Personal Loan'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-tuning",
   "metadata": {},
   "source": [
    "### Splitting in to train and test set\n",
    "* its a good practice to select the features by examining only the training set. And this is to avoid the overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "positive-timeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 13), (500, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=[target], axis=1),  # drop the target\n",
    "    data[target],  # just the target\n",
    "    test_size=0.1,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beautiful-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "PROF_DATA = {}\n",
    "\n",
    "def profile(fn):\n",
    "    @wraps(fn)\n",
    "    def with_profiling(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        ret = fn(*args, **kwargs)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        if fn.__name__ not in PROF_DATA:\n",
    "            PROF_DATA[fn.__name__] = [0, []]\n",
    "        PROF_DATA[fn.__name__][0] += 1\n",
    "        PROF_DATA[fn.__name__][1].append(elapsed_time)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    return with_profiling\n",
    "\n",
    "def print_prof_data():\n",
    "    for fname, data in PROF_DATA.items():\n",
    "        max_time = max(data[1])\n",
    "        avg_time = sum(data[1]) / len(data[1])\n",
    "        print(\"Function %s called %d times. \" % (fname, data[0]))\n",
    "        print('Execution time max: %.3f, average: %.3f' % (max_time, avg_time))\n",
    "        print('')\n",
    "\n",
    "def clear_prof_data():\n",
    "    global PROF_DATA\n",
    "    PROF_DATA = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-keyboard",
   "metadata": {},
   "source": [
    "## 1. Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-blind",
   "metadata": {},
   "source": [
    "**Remove constand, quasi constant and duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decimal-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def remove_constant_and_quasi_constant_features(df):\n",
    "    # remove constant and quasi-constant features first:\n",
    "    # we use Feature-engine for this\n",
    "    sel = DropConstantFeatures(tol=0.998, variables=None, missing_values='raise')\n",
    "    sel.fit_transform(df)\n",
    "    return sel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "disciplinary-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = remove_constant_and_quasi_constant_features(X_train)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "numerical-technique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function remove_constant_and_quasi_constant_features called 1 times. \n",
      "Execution time max: 0.069, average: 0.069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_prof_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "possible-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def remove_duplicate_features(df):\n",
    "    # set up the selector\n",
    "    sel = DropDuplicateFeatures(variables=None, missing_values='raise')\n",
    "    # find the duplicate features, this might take a while\n",
    "    sel.fit(df)\n",
    "    return sel.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "optimum-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = remove_duplicate_features(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "becoming-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function remove_constant_and_quasi_constant_features called 1 times. \n",
      "Execution time max: 0.069, average: 0.069\n",
      "\n",
      "Function remove_duplicate_features called 1 times. \n",
      "Execution time max: 0.047, average: 0.047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_prof_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-procedure",
   "metadata": {},
   "source": [
    "**Remove Correlated features**\n",
    "*  \"Good feature subsets contain features highly correlated with the target, yet uncorrelated to each other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bronze-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def remove_corr_features_brute_force(df, print_res=False):\n",
    "    sel = DropCorrelatedFeatures(\n",
    "        threshold=0.8,\n",
    "        method='pearson',\n",
    "        missing_values='ignore'\n",
    "    )\n",
    "    # find correlated features\n",
    "    sel.fit(df)\n",
    "    if (print_res):\n",
    "        sel.correlated_feature_sets_\n",
    "    return sel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "refined-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_corr_features_brute_force(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "marked-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smart correlation selection\n",
    "@profile\n",
    "def remove_corr_features_smart(x_train, y_train, print_res=False):\n",
    "    # random forest\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        random_state=20,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "\n",
    "    # correlation selector\n",
    "    sel = SmartCorrelatedSelection(\n",
    "        variables=None, # if none, selector examines all numerical variables\n",
    "        method=\"pearson\",\n",
    "        threshold=0.8,\n",
    "        missing_values=\"raise\",\n",
    "        selection_method=\"model_performance\", # this can be set to variance also to select feature with mst variance\n",
    "        estimator=rf,\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=3,\n",
    "    )\n",
    "\n",
    "    # this may take a while, because we are training\n",
    "    # a random forest per correlation group\n",
    "    sel.fit(x_train, y_train)\n",
    "    \n",
    "    if (print_res):\n",
    "        sel.correlated_feature_sets_\n",
    "    return sel.fit_transform(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unlimited-college",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = remove_corr_features_smart(df, y_train)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-surge",
   "metadata": {},
   "source": [
    "**Statistical Techniques and Ranking Methods**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-seeking",
   "metadata": {},
   "source": [
    "**Mutual Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "great-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def selectkbest_mi_clf(x_train, y_train, k=10, print_res=False):\n",
    "    sel = SelectKBest(mutual_info_classif, k=k).fit(x_train, y_train)\n",
    "    \n",
    "    if print_res:\n",
    "        # display features\n",
    "        x_train.columns[sel.get_support()]\n",
    "        \n",
    "    return sel.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "employed-toyota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = selectkbest_mi_clf(X_train, y_train)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-investor",
   "metadata": {},
   "source": [
    "**Chi-Square Test**\n",
    "NOTE: to be used only with the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "existing-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to determine the chi2 value\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "@profile\n",
    "def chi_square_test(x_train, y_train, k=1, print_res=False):\n",
    "    sel = SelectKBest(chi2, k=1).fit(x_train, y_train)\n",
    "    \n",
    "    if print_res:\n",
    "        # display features\n",
    "        x_train.columns[sel.get_support()]\n",
    "        \n",
    "    return sel.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brazilian-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some error in above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-vulnerability",
   "metadata": {},
   "source": [
    "**ANNOVA**\n",
    "* ANOVA assumes a linear relationship between the feature and the target and that the variables follow a Gaussian distribution. If this is not true, the result of this test may not be useful.\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "israeli-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def annova_clf(x_train, y_train, k=10, print_res=False):\n",
    "    # calculate the univariate statistical measure between\n",
    "    # each of the variables and the target\n",
    "\n",
    "    # similarly to chi2, the output is one array with f-scores\n",
    "    # and one array with the pvalues\n",
    "\n",
    "    sel = SelectKBest(f_classif, k=k).fit(x_train, y_train)\n",
    "    \n",
    "    if print_res:\n",
    "        # display features\n",
    "        print(x_train.columns[sel.get_support()])\n",
    "        \n",
    "    return sel.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "relevant-thumb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 10)\n"
     ]
    }
   ],
   "source": [
    "df = annova_clf(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-empty",
   "metadata": {},
   "source": [
    "**Feature Selection with ML models**\n",
    "* Idea is that a single feature is taken out to build a model and then this feature will be ranked as per the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "responsible-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def select_by_single_feature_perf_clf(x_train, y_train, print_res=False):\n",
    "    # set up a machine learning model\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=10, random_state=1, n_jobs=4)\n",
    "\n",
    "    # set up the selector\n",
    "    sel = SelectBySingleFeaturePerformance(\n",
    "        variables=None,\n",
    "        estimator=rf,\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=3,\n",
    "        threshold=0.5)\n",
    "\n",
    "    # find predictive features\n",
    "    sel.fit(X_train, y_train)\n",
    "    \n",
    "    if print_res:\n",
    "        print(sel.feature_performance_)\n",
    "        \n",
    "    return sel.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hindu-suffering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 9)\n"
     ]
    }
   ],
   "source": [
    "df = select_by_single_feature_perf_clf(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-toner",
   "metadata": {},
   "source": [
    "## 2. Wrapper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "coated-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def step_forward_selection_clf(x_train, y_train, k = 10, print_res=False):\n",
    "    # review to increase the n_estimators\n",
    "    sfs = SFS(RandomForestClassifier(n_estimators=10, n_jobs=4, random_state=0), \n",
    "           k_features=k, # the more features we want, the longer it will take to run\n",
    "           forward=True, \n",
    "           floating=False, # see the docs for more details in this parameter\n",
    "           verbose=2, # this indicates how much to print out intermediate steps\n",
    "           scoring='roc_auc',\n",
    "           cv=2)\n",
    "\n",
    "    sfs = sfs.fit(np.array(x_train), y_train)\n",
    "    selected_feat = x_train.columns[list(sfs.k_feature_idx_)]\n",
    "    if print_res:\n",
    "        print(selected_feat)\n",
    "        \n",
    "    return x_train[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ceramic-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    4.9s finished\n",
      "\n",
      "[2021-06-03 18:57:25] Features: 1/10 -- score: 0.8813161971181842[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    4.6s finished\n",
      "\n",
      "[2021-06-03 18:57:30] Features: 2/10 -- score: 0.9096032051152344[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    3.7s finished\n",
      "\n",
      "[2021-06-03 18:57:33] Features: 3/10 -- score: 0.9394566862040203[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.8s finished\n",
      "\n",
      "[2021-06-03 18:57:37] Features: 4/10 -- score: 0.9816553466924767[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    3.3s finished\n",
      "\n",
      "[2021-06-03 18:57:41] Features: 5/10 -- score: 0.9876823617490541[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.1s finished\n",
      "\n",
      "[2021-06-03 18:57:44] Features: 6/10 -- score: 0.9870427326215352[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.6s finished\n",
      "\n",
      "[2021-06-03 18:57:47] Features: 7/10 -- score: 0.9884293451501723[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.9s finished\n",
      "\n",
      "[2021-06-03 18:57:49] Features: 8/10 -- score: 0.9890223229441376[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "\n",
      "[2021-06-03 18:57:51] Features: 9/10 -- score: 0.9897338962968958[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.5s finished\n",
      "\n",
      "[2021-06-03 18:57:52] Features: 10/10 -- score: 0.9890779673058461"
     ]
    }
   ],
   "source": [
    "df = step_forward_selection_clf(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fixed-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def step_backward_selection_clf(x_train, y_train, k = 10, print_res=False):\n",
    "    # review to increase the n_estimators\n",
    "    sfs = SFS(RandomForestClassifier(n_estimators=10, n_jobs=4, random_state=0), \n",
    "           k_features=k, # the more features we want, the longer it will take to run\n",
    "           forward=False, \n",
    "           floating=False, # see the docs for more details in this parameter\n",
    "           verbose=2, # this indicates how much to print out intermediate steps\n",
    "           scoring='roc_auc',\n",
    "           cv=2)\n",
    "\n",
    "    sfs = sfs.fit(np.array(x_train), y_train)\n",
    "    selected_feat = x_train.columns[list(sfs.k_feature_idx_)]\n",
    "    if print_res:\n",
    "        print(selected_feat)\n",
    "        \n",
    "    return x_train[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "innocent-cookie",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    5.2s finished\n",
      "\n",
      "[2021-06-03 18:57:58] Features: 12/10 -- score: 0.988945320140561[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    4.2s finished\n",
      "\n",
      "[2021-06-03 18:58:03] Features: 11/10 -- score: 0.9921873067904108[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    3.6s finished\n",
      "\n",
      "[2021-06-03 18:58:06] Features: 10/10 -- score: 0.9915173261928689"
     ]
    }
   ],
   "source": [
    "df = step_backward_selection_clf(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "attractive-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def exhaustive_selection_clf(x_train, y_train, min_features=1, max_features=2, print_res=False):\n",
    "    # review to increase the n_estimators\n",
    "    efs = EFS(RandomForestClassifier(n_estimators=5, n_jobs=4, random_state=0, max_depth=2),\n",
    "              min_features=min_features,\n",
    "              max_features=max_features,\n",
    "              scoring='roc_auc',\n",
    "              print_progress=True,\n",
    "              cv=2)\n",
    "\n",
    "    # search features\n",
    "    efs = efs.fit(np.array(x_train), y_train)\n",
    "    selected_feat = x_train.columns[list(efs.best_idx_)]\n",
    "    if print_res:\n",
    "        print(selected_feat)\n",
    "        \n",
    "    return x_train[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "necessary-motel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 91/91"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 2)\n"
     ]
    }
   ],
   "source": [
    "df = exhaustive_selection_clf(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-outdoors",
   "metadata": {},
   "source": [
    "## Embedded Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "brilliant-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def log_reg_selection(x_train, y_train, print_res=False):\n",
    "    sel = SelectFromModel(LogisticRegression(C=1000, penalty='l2', max_iter=300, random_state=10))\n",
    "\n",
    "    sel.fit(x_train, y_train)\n",
    "    \n",
    "    selected_feat = x_train.columns[(sel.get_support())]\n",
    "    \n",
    "    if print_res:\n",
    "        print(selected_feat)\n",
    "    \n",
    "    return x_train[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "appointed-scroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 4)\n"
     ]
    }
   ],
   "source": [
    "df = log_reg_selection(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "endangered-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def log_reg_lasso_selection(x_train, y_train, print_res=True):\n",
    "    sel = SelectFromModel(LogisticRegression(C=0.5, penalty='l1', solver='liblinear', random_state=10))\n",
    "\n",
    "    sel.fit(x_train, y_train)\n",
    "    \n",
    "    selected_feat = x_train.columns[(sel.get_support())]\n",
    "    \n",
    "    if print_res:\n",
    "        print(selected_feat)\n",
    "    \n",
    "    return x_train[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "controlled-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Age', 'Income', 'ZIP Code', 'Family', 'CCAvg', 'Education',\n",
      "       'Mortgage', 'Securities Account', 'CD Account', 'Online', 'CreditCard'],\n",
      "      dtype='object')\n",
      "(4500, 12)\n"
     ]
    }
   ],
   "source": [
    "df = log_reg_lasso_selection(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "devoted-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def random_forest_selection_clf(x_train, y_train, print_res=False):\n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators=10, random_state=10))\n",
    "\n",
    "    sel.fit(x_train, y_train)\n",
    "    selected_feat = x_train.columns[(sel.get_support())]\n",
    "    if print_res:\n",
    "        print(selected_feat)\n",
    "    return sel.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "flexible-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 4)\n"
     ]
    }
   ],
   "source": [
    "df = random_forest_selection_clf(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pediatric-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def random_forest_selection_clf_rfe(x_train, y_train, print_res=False):\n",
    "    sel = RFE(RandomForestClassifier(n_estimators=10, random_state=10), n_features_to_select=27)\n",
    "\n",
    "    sel.fit(x_train, y_train)\n",
    "    selected_feat = x_train.columns[(sel.get_support())]\n",
    "    if print_res:\n",
    "        print(selected_feat)\n",
    "    return sel.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "possible-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 13)\n"
     ]
    }
   ],
   "source": [
    "df = random_forest_selection_clf_rfe(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-pantyhose",
   "metadata": {},
   "source": [
    "## Hybrid Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-question",
   "metadata": {},
   "source": [
    "**Feature Shuffling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "geological-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a classifier, can be any classifier, chossing RF as a good default classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=2, random_state=2909, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "medium-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def feature_shuffling_selection_clf(x_train, y_train, model=rf,print_res=False):\n",
    "    sel = SelectByShuffling(\n",
    "        variables=None, # automatically examine all numerical variables\n",
    "        estimator=model, # the ML model\n",
    "        scoring='roc_auc', # the metric to evaluate\n",
    "        threshold=0,# the maximum performance drop allowed to select the feature\n",
    "        cv=3, # cross validation\n",
    "        random_state=1 # seed\n",
    "    )\n",
    "\n",
    "    sel.fit(X_train, y_train)\n",
    "    \n",
    "    df = sel.transform(x_train)\n",
    "    \n",
    "    if print_res:\n",
    "        print(df.columns)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "successful-oriental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 2)\n"
     ]
    }
   ],
   "source": [
    "df = feature_shuffling_selection_clf(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-garbage",
   "metadata": {},
   "source": [
    "**Recursive Feature Elimination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "first-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ML model for which we want to select features\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hollow-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def rfe_selection_clf(x_train, y_train, model = model,print_res=False):\n",
    "    # Setup the RFE selector\n",
    "    sel = RecursiveFeatureElimination(\n",
    "        variables=None, # automatically evaluate all numerical variables\n",
    "        estimator = model, # the ML model\n",
    "        scoring = 'roc_auc', # the metric we want to evalute\n",
    "        threshold = 0.0005, # the maximum performance drop allowed to remove a feature\n",
    "        cv=2, # cross-validation\n",
    "    )\n",
    "\n",
    "    # this may take quite a while, because\n",
    "    # we are building a lot of models with cross-validation\n",
    "    sel.fit(x_train, y_train)\n",
    "    \n",
    "    df = sel.transform(x_train)\n",
    "    \n",
    "    if print_res:\n",
    "        print(df.columns)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "proprietary-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 5)\n"
     ]
    }
   ],
   "source": [
    "df = rfe_selection_clf(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-sudan",
   "metadata": {},
   "source": [
    "**Recursive Feature Addition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "technical-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ML model for which we want to select features\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "trying-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def rfa_selection_clf(x_train, y_train, model=model, print_res=False):\n",
    "    # Setup the RFA selector\n",
    "\n",
    "    rfa = RecursiveFeatureAddition(\n",
    "        variables=None,  # automatically evaluate all numerical variables\n",
    "        estimator=model,  # the ML model\n",
    "        scoring='roc_auc',  # the metric we want to evalute\n",
    "        threshold=0.0001,  # the minimum performance increase needed to select a feature\n",
    "        cv=2,  # cross-validation\n",
    "    )\n",
    "\n",
    "    rfa.fit(X_train, y_train)\n",
    "    df = rfa.transform(x_train)\n",
    "    if print_res:\n",
    "        print(df.columns)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "variable-squad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 5)\n"
     ]
    }
   ],
   "source": [
    "df = rfa_selection_clf(X_train, y_train)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "superb-guard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function remove_constant_and_quasi_constant_features called 1 times. \n",
      "Execution time max: 0.069, average: 0.069\n",
      "\n",
      "Function remove_duplicate_features called 1 times. \n",
      "Execution time max: 0.047, average: 0.047\n",
      "\n",
      "Function remove_corr_features_brute_force called 1 times. \n",
      "Execution time max: 0.000, average: 0.000\n",
      "\n",
      "Function remove_corr_features_smart called 1 times. \n",
      "Execution time max: 0.038, average: 0.038\n",
      "\n",
      "Function selectkbest_mi_clf called 1 times. \n",
      "Execution time max: 0.479, average: 0.479\n",
      "\n",
      "Function annova_clf called 1 times. \n",
      "Execution time max: 0.015, average: 0.015\n",
      "\n",
      "Function select_by_single_feature_perf_clf called 1 times. \n",
      "Execution time max: 8.780, average: 8.780\n",
      "\n",
      "Function step_forward_selection_clf called 1 times. \n",
      "Execution time max: 32.296, average: 32.296\n",
      "\n",
      "Function step_backward_selection_clf called 1 times. \n",
      "Execution time max: 13.781, average: 13.781\n",
      "\n",
      "Function exhaustive_selection_clf called 1 times. \n",
      "Execution time max: 29.085, average: 29.085\n",
      "\n",
      "Function log_reg_selection called 1 times. \n",
      "Execution time max: 0.301, average: 0.301\n",
      "\n",
      "Function log_reg_lasso_selection called 1 times. \n",
      "Execution time max: 0.053, average: 0.053\n",
      "\n",
      "Function random_forest_selection_clf called 1 times. \n",
      "Execution time max: 0.053, average: 0.053\n",
      "\n",
      "Function random_forest_selection_clf_rfe called 1 times. \n",
      "Execution time max: 0.031, average: 0.031\n",
      "\n",
      "Function feature_shuffling_selection_clf called 1 times. \n",
      "Execution time max: 5.989, average: 5.989\n",
      "\n",
      "Function rfe_selection_clf called 1 times. \n",
      "Execution time max: 0.977, average: 0.977\n",
      "\n",
      "Function rfa_selection_clf called 1 times. \n",
      "Execution time max: 0.632, average: 0.632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_prof_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "military-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_techniques =[\n",
    "    #{'Method Name', 'Type of Method':, 'Test DataSet Size':, 'Execution Time':}\n",
    "    {'Method Name': 'Drop Constant Feature', 'Type of Method':'Filter', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.069},\n",
    "    {'Method Name': 'Drop Duplicate Feature', 'Type of Method':'Filter', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.047},\n",
    "    {'Method Name':'Drop Correlated Feature', 'Type of Method':'Filter', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.000},\n",
    "    {'Method Name':'Smart correlated Selection', 'Type of Method':'Filter', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.038},\n",
    "    \n",
    "    {'Method Name':'SelectKBest Mutual Information', 'Type of Method':'Statistical Techniques and Ranking Methods','Test DataSet Size': '(4500, 201)', 'Execution Time':0.479},\n",
    "    {'Method Name':'ANNOVA ', 'Type of Method':'Statistical Techniques and Ranking Methods', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.015},\n",
    "    \n",
    "    {'Method Name':'SelectBySingleFeaturePerformance', 'Type of Method':'Feature Selection with ML Models', 'Test DataSet Size':'(4500, 201)', 'Execution Time':8.780},\n",
    "    \n",
    "    {'Method Name':'Step Forward Feature Selection', 'Type of Method':'Wrapper', 'Test DataSet Size':'(4500, 201)', 'Execution Time':32.296},\n",
    "    {'Method Name':'Step Backward Feature Selection', 'Type of Method':'Wrapper', 'Test DataSet Size':'(4500, 201)','Execution Time': 13.781},\n",
    "    {'Method Name':'Exhaustive Selection', 'Type of Method':'Wrapper', 'Test DataSet Size':'(4500, 201)', 'Execution Time':29.085},\n",
    "    \n",
    "    {'Method Name':'Logistic Regression Selection', 'Type of Method':'Embedded', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.301},\n",
    "    {'Method Name':'Logistic Regression Lasso Selection', 'Type of Method':'Embedded', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.053},\n",
    "    {'Method Name':'Random Forest Selection', 'Type of Method':'Embedded', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.053},\n",
    "    {'Method Name':'Random Forest Selection using RFE', 'Type of Method':'Embedded', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.031},\n",
    "    \n",
    "    \n",
    "    {'Method Name':'Feature Shuffling Selection', 'Type of Method':'Hybrid', 'Test DataSet Size':'(4500, 201)', 'Execution Time':5.989},\n",
    "    {'Method Name':'Recursive Feature Selection', 'Type of Method':'Hybrid', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.977},\n",
    "    {'Method Name':'Recursive Feature Addition', 'Type of Method':'Hybrid', 'Test DataSet Size':'(4500, 201)', 'Execution Time':0.632}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "placed-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "exec_res = pd.DataFrame(all_techniques).sort_values('Execution Time', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "patient-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Type of Method</th>\n",
       "      <th>Test DataSet Size</th>\n",
       "      <th>Execution Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Step Forward Feature Selection</td>\n",
       "      <td>Wrapper</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>32.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Exhaustive Selection</td>\n",
       "      <td>Wrapper</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>29.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Step Backward Feature Selection</td>\n",
       "      <td>Wrapper</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>13.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SelectBySingleFeaturePerformance</td>\n",
       "      <td>Feature Selection with ML Models</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>8.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Feature Shuffling Selection</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>5.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Recursive Feature Selection</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Recursive Feature Addition</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SelectKBest Mutual Information</td>\n",
       "      <td>Statistical Techniques and Ranking Methods</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression Selection</td>\n",
       "      <td>Embedded</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop Constant Feature</td>\n",
       "      <td>Filter</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression Lasso Selection</td>\n",
       "      <td>Embedded</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest Selection</td>\n",
       "      <td>Embedded</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drop Duplicate Feature</td>\n",
       "      <td>Filter</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smart correlated Selection</td>\n",
       "      <td>Filter</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest Selection using RFE</td>\n",
       "      <td>Embedded</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ANNOVA</td>\n",
       "      <td>Statistical Techniques and Ranking Methods</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drop Correlated Feature</td>\n",
       "      <td>Filter</td>\n",
       "      <td>(4500, 201)</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Method Name  \\\n",
       "7        Step Forward Feature Selection   \n",
       "9                  Exhaustive Selection   \n",
       "8       Step Backward Feature Selection   \n",
       "6      SelectBySingleFeaturePerformance   \n",
       "14          Feature Shuffling Selection   \n",
       "15          Recursive Feature Selection   \n",
       "16           Recursive Feature Addition   \n",
       "4        SelectKBest Mutual Information   \n",
       "10        Logistic Regression Selection   \n",
       "0                 Drop Constant Feature   \n",
       "11  Logistic Regression Lasso Selection   \n",
       "12              Random Forest Selection   \n",
       "1                Drop Duplicate Feature   \n",
       "3            Smart correlated Selection   \n",
       "13    Random Forest Selection using RFE   \n",
       "5                               ANNOVA    \n",
       "2               Drop Correlated Feature   \n",
       "\n",
       "                                Type of Method Test DataSet Size  \\\n",
       "7                                      Wrapper       (4500, 201)   \n",
       "9                                      Wrapper       (4500, 201)   \n",
       "8                                      Wrapper       (4500, 201)   \n",
       "6             Feature Selection with ML Models       (4500, 201)   \n",
       "14                                      Hybrid       (4500, 201)   \n",
       "15                                      Hybrid       (4500, 201)   \n",
       "16                                      Hybrid       (4500, 201)   \n",
       "4   Statistical Techniques and Ranking Methods       (4500, 201)   \n",
       "10                                    Embedded       (4500, 201)   \n",
       "0                                       Filter       (4500, 201)   \n",
       "11                                    Embedded       (4500, 201)   \n",
       "12                                    Embedded       (4500, 201)   \n",
       "1                                       Filter       (4500, 201)   \n",
       "3                                       Filter       (4500, 201)   \n",
       "13                                    Embedded       (4500, 201)   \n",
       "5   Statistical Techniques and Ranking Methods       (4500, 201)   \n",
       "2                                       Filter       (4500, 201)   \n",
       "\n",
       "    Execution Time  \n",
       "7           32.296  \n",
       "9           29.085  \n",
       "8           13.781  \n",
       "6            8.780  \n",
       "14           5.989  \n",
       "15           0.977  \n",
       "16           0.632  \n",
       "4            0.479  \n",
       "10           0.301  \n",
       "0            0.069  \n",
       "11           0.053  \n",
       "12           0.053  \n",
       "1            0.047  \n",
       "3            0.038  \n",
       "13           0.031  \n",
       "5            0.015  \n",
       "2            0.000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "banner-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_res.to_excel('./feature_selection_techniques_execution_time.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-leisure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
