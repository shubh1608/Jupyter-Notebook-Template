{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "through-nepal",
   "metadata": {},
   "source": [
    "# Imbalanced Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-skiing",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weekly-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "import math\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import (\n",
    "    RandomUnderSampler,\n",
    "    CondensedNearestNeighbour,\n",
    "    TomekLinks,\n",
    "    OneSidedSelection,\n",
    "    EditedNearestNeighbours,\n",
    "    RepeatedEditedNearestNeighbours,\n",
    "    AllKNN,\n",
    "    NeighbourhoodCleaningRule,\n",
    "    NearMiss,\n",
    "    InstanceHardnessThreshold\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import (\n",
    "    RandomOverSampler,\n",
    "    SMOTE,\n",
    "    ADASYN,\n",
    "    BorderlineSMOTE,\n",
    "    SVMSMOTE,\n",
    "    SMOTENC,\n",
    "    KMeansSMOTE\n",
    ")\n",
    "\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "\n",
    "from imblearn.ensemble import (\n",
    "    BalancedBaggingClassifier,\n",
    "    BalancedRandomForestClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# adding common folder location to sys.path\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "\n",
    "from helper import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-salad",
   "metadata": {},
   "source": [
    "### Loading Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescription-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-investment",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "korean-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to your dataset, can be a csv file or xlsx\n",
    "dataset_path = \"../dataset/Bank_Personal_Loan_Modelling_transformed.xlsx\"\n",
    "\n",
    "## use code as per the type of data source\n",
    "\n",
    "## use below line to read data from csv file\n",
    "## df = pd.read_csv(dataset_path)\n",
    "df = pd.read_excel(dataset_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opponent-escape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "      <th>Personal Loan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.254237</td>\n",
       "      <td>-0.863923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.508475</td>\n",
       "      <td>-1.241379</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.898305</td>\n",
       "      <td>0.475714</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.277778</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.250278</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.781238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Experience    Income  ZIP Code  Family     CCAvg  Education  \\\n",
       "ID                                                                     \n",
       "1  -1.0       -0.95 -0.254237 -0.863923     1.0  0.055556       -0.5   \n",
       "2   0.0       -0.05 -0.508475 -1.241379     0.5  0.000000       -0.5   \n",
       "3  -0.3       -0.25 -0.898305  0.475714    -0.5 -0.277778       -0.5   \n",
       "4  -0.5       -0.55  0.610169  0.250278    -0.5  0.666667        0.0   \n",
       "5  -0.5       -0.60 -0.322034 -0.781238     1.0 -0.277778        0.0   \n",
       "\n",
       "    Mortgage  Securities Account  CD Account  Online  CreditCard  \\\n",
       "ID                                                                 \n",
       "1        0.0                   1           0      -1           0   \n",
       "2        0.0                   1           0      -1           0   \n",
       "3        0.0                   0           0      -1           0   \n",
       "4        0.0                   0           0      -1           0   \n",
       "5        0.0                   0           0      -1           1   \n",
       "\n",
       "    Personal Loan  \n",
       "ID                 \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amazing-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Personal Loan'\n",
    "# df_x = df.drop(columns=[target])\n",
    "# df_y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-toolbox",
   "metadata": {},
   "source": [
    "### 5. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "competent-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for testing\n",
    "def run_method(method, df):\n",
    "    class_cnt = df[target].value_counts()\n",
    "    print('Before run size majority:{0}, minority:{1}'.format(class_cnt[0], class_cnt[1]))\n",
    "    df_sampled = method(df)\n",
    "    class_cnt = df_sampled[target].value_counts()\n",
    "    print('After run size majority:{0}, minority:{1}'.format(class_cnt[0], class_cnt[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-spoke",
   "metadata": {},
   "source": [
    "1. Under Sampling\n",
    "* refer notebook example [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-01-Random-Undersampling.ipynb)\n",
    "* documentation [here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "married-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imblearn random under sampling\n",
    "# params: strategy: 'majority'(it specifies to undersample majority class to have 1:1 ratio)\n",
    "#         strategy: 0.5 (resultant ratio will be 1:0.5)\n",
    "\n",
    "def apply_random_undersampling(df, strategy='auto'):\n",
    "    # define oversampling strategy\n",
    "    rus = RandomUnderSampler(\n",
    "        sampling_strategy=strategy,  # 'auto' - samples only the majority class\n",
    "        random_state=0,  # for reproducibility\n",
    "        replacement=True # if it should resample with replacement\n",
    "    )  \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_under, y_train_under = rus.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_under[target] = y_train_under\n",
    "    return x_train_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "middle-senegal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:3, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_random_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-village",
   "metadata": {},
   "source": [
    "2. Condensed Nearest Neighbour\n",
    "* refere example notebook [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-02-Condensed-Nearest-Neighbours.ipynb)\n",
    "* refer doc here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "several-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cnn_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    cnn = CondensedNearestNeighbour(\n",
    "        sampling_strategy=strategy,  # undersamples only the majority class\n",
    "        random_state=0,            # for reproducibility\n",
    "        n_neighbors=1,             # default\n",
    "        n_jobs=4                   # I have 4 cores in my laptop\n",
    "    )   \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = cnn.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "material-reserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:2, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_cnn_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-trace",
   "metadata": {},
   "source": [
    "3. Tomet Link\n",
    "* refere notebook example [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-03-Tomek-Links.ipynb)\n",
    "* refer doc here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ahead-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tometlink_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    tl = TomekLinks(\n",
    "        sampling_strategy=strategy,  # undersamples only the majority class\n",
    "        n_jobs=4                   # I have 4 cores in my laptop\n",
    "    )    \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = tl.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "inappropriate-worcester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:17, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_tometlink_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-indie",
   "metadata": {},
   "source": [
    "4. One Sided Selection\n",
    "* refer notebook example [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-04-One-Sised-Selection.ipynb)\n",
    "* refer doc here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "english-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_onesidedselection_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    oss = OneSidedSelection(\n",
    "        sampling_strategy=strategy,  # undersamples only the majority class\n",
    "        random_state=0,            # for reproducibility\n",
    "        n_neighbors=1,             # default\n",
    "        n_jobs=4                   # I have 4 cores in my laptop\n",
    "    )   \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = oss.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "opposite-phrase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:3, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_onesidedselection_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-hazard",
   "metadata": {},
   "source": [
    "5. EditedNearestNeighbours\n",
    "* refer notebook [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-05-Edited-Nearest-Neighbours.ipynb)\n",
    "* refer doc [here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "preliminary-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_editednearestneighbour_undersampling(df, strategy='majority'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    enn = EditedNearestNeighbours(\n",
    "        sampling_strategy='auto',  # undersamples only the majority class\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',            # all neighbours need to have the same label as the observation examined\n",
    "        n_jobs=4                   # I have 4 cores in my laptop \n",
    "    ) \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = enn.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "duplicate-intellectual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:17, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_editednearestneighbour_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-mirror",
   "metadata": {},
   "source": [
    "6. Repeated Edited Nearest Neighbours\n",
    "* refer notebook [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-05-Edited-Nearest-Neighbours.ipynb)\n",
    "* refer doc [here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "consistent-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_repeated_enn_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    renn = RepeatedEditedNearestNeighbours(\n",
    "        sampling_strategy=strategy, # removes only the majority class\n",
    "        n_neighbors=3,            # 3 KNN\n",
    "        kind_sel='all',           # all neighbouring observations should show the same class\n",
    "        n_jobs=4,                 # 4 processors in my laptop\n",
    "        max_iter=100              # maximum number of iterations \n",
    "    )\n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = renn.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "invalid-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:17, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_repeated_enn_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-galaxy",
   "metadata": {},
   "source": [
    "7. All K Nearest Neighbours\n",
    "* refer notebook [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-07-All-KNN.ipynb)\n",
    "* refer doc [here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adopted-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_allknn_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    allknn = AllKNN(\n",
    "        sampling_strategy=strategy,  # undersamples only the majority class\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',            # all neighbours need to have the same label as the observation examined\n",
    "        n_jobs=4                   # I have 4 cores in my laptop\n",
    "    )  \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = allknn.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "prompt-drink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:17, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_allknn_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-retrieval",
   "metadata": {},
   "source": [
    "8. Neighbourd Cleaning Rule\n",
    "* refer notebook [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-08-Neighbourhood-Cleaning-Rule.ipynb)\n",
    "* refer doc [here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "indonesian-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_neighbourhood_cleaning_rule_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    ncr = NeighbourhoodCleaningRule(\n",
    "        sampling_strategy=strategy,# removes only the majority class\n",
    "        n_neighbors=3,           # 3 KNN\n",
    "        kind_sel='all',          # all neighbouring observations should show the same class\n",
    "        n_jobs=4,                # 4 processors in my laptop\n",
    "        threshold_cleaning=0.5   # threshold no exclude or not observations\n",
    "    )   \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = ncr.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "rubber-casino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:14, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_neighbourhood_cleaning_rule_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-warren",
   "metadata": {},
   "source": [
    "9. NearMiss [v1|v2|v3]\n",
    "* refer notebook [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-09-NearMiss.ipynb)\n",
    "* refer doc [here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "compliant-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nearmiss_v1_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    nm1 = NearMiss(\n",
    "        sampling_strategy=strategy,  # undersamples only the majority class\n",
    "        version=1,\n",
    "        n_neighbors=3,\n",
    "        n_jobs=4                   # I have 4 cores in my laptop  \n",
    "    )  \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = nm1.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "directed-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:3, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_nearmiss_v1_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "pediatric-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nearmiss_v2_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    nm2 = NearMiss(\n",
    "        sampling_strategy=strategy,  # undersamples only the majority class\n",
    "        version=2,\n",
    "        n_neighbors=3,\n",
    "        n_jobs=4                   # I have 4 cores in my laptop  \n",
    "    )  \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = nm2.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "neither-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:3, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_nearmiss_v2_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "premier-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nearmiss_v3_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    nm3 = NearMiss(\n",
    "        sampling_strategy=strategy,  # undersamples only the majority class\n",
    "        version=3,\n",
    "        n_neighbors=3,\n",
    "        n_jobs=4                   # I have 4 cores in my laptop  \n",
    "    )  \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = nm3.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "whole-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:3, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_nearmiss_v3_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-angola",
   "metadata": {},
   "source": [
    "10. InstanceHardnessThreshold\n",
    "* refer notebook [here](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-04-Undersampling/04-10-Instance-Hardness-Class.ipynb)\n",
    "* refer doc [here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "double-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_instance_hardness_sampling_undersampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    iht = InstanceHardnessThreshold(\n",
    "        # TODO - review if we need to pass classifier as a parameter \n",
    "        # select a classifier, in this case Random Forests\n",
    "        estimator=RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "        sampling_strategy='auto',  # undersamples only the majority class\n",
    "        random_state=0,\n",
    "        n_jobs=4,                  # have 4 processors in my laptop\n",
    "        cv=3                       # cross validation fold \n",
    "    )  \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = iht.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "administrative-music",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:4, minority:3\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_instance_hardness_sampling_undersampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-mexico",
   "metadata": {},
   "source": [
    "<!-- #### COMPARISON\n",
    "![image.png](attachment:image.png)\n",
    "![image-2.png](attachment:image-2.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "asian-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON\n",
    "# ![image.png](attachment:image.png)\n",
    "# ![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-scoop",
   "metadata": {},
   "source": [
    "#### OVER SAMPLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-anthony",
   "metadata": {},
   "source": [
    "1. Random Over Sampler [Notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-05-Oversampling/05-01-Random-Oversampling.ipynb), [Document]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "later-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_oversampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    ros = RandomOverSampler(\n",
    "        sampling_strategy=strategy, # samples only the minority class\n",
    "        random_state=0,  # for reproducibility\n",
    "    )  \n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    x_train_resampled, y_train_resampled = ros.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aquatic-smooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:17, minority:3\n",
      "After run size majority:17, minority:17\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_random_oversampling, df[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-directive",
   "metadata": {},
   "source": [
    "2. SMOTE [Notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-05-Oversampling/05-02-SMOTE.ipynb) [Document]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "electoral-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote_oversampling(df, strategy='auto'):\n",
    "    sm = SMOTE(\n",
    "        random_state=42,\n",
    "        sampling_strategy=strategy,\n",
    "        n_jobs=4\n",
    "    )\n",
    "\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    \n",
    "    x_train_sm, y_train_sm = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "    x_train_sm[target] = y_train_sm\n",
    "    return x_train_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "logical-ozone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:88, minority:12\n",
      "After run size majority:88, minority:88\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_smote_oversampling, df[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-berkeley",
   "metadata": {},
   "source": [
    "3. SMOTE Nominal Continous for categorical data [notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-05-Oversampling/05-03-SMOTE-NC.ipynb), [Document]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "impressive-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smotenc_oversampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    smnc = SMOTENC(\n",
    "        sampling_strategy=strategy,  # samples only the minority class\n",
    "        random_state=0,            # for reproducibility\n",
    "        k_neighbors=5,\n",
    "        n_jobs=4,\n",
    "        categorical_features=[2,3] # indeces of the columns of categorical variables\n",
    "    )    \n",
    "    \n",
    "    #separate train and test\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train_resampled, y_train_resampled = smnc.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "returning-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:88, minority:12\n",
      "After run size majority:88, minority:88\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_smotenc_oversampling, df[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-fifty",
   "metadata": {},
   "source": [
    "4. ADASYN [notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-05-Oversampling/05-04-ADASYN.ipynb), [Document]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "sonic-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_adasyn_oversampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    ada = ADASYN(\n",
    "        sampling_strategy=strategy,  # samples only the minority class\n",
    "        random_state=0,  # for reproducibility\n",
    "        n_neighbors=5,\n",
    "        n_jobs=4\n",
    "    )   \n",
    "    \n",
    "    #separate train and test\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train_resampled, y_train_resampled = ada.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "involved-child",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:88, minority:12\n",
      "After run size majority:88, minority:84\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_adasyn_oversampling, df[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-student",
   "metadata": {},
   "source": [
    "5. BORDERLINE SMOTE [notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-05-Oversampling/05-05-Borderline-SMOTE.ipynb), [Document]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "compact-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_borderline1_oversampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    sm_b1 = BorderlineSMOTE(\n",
    "        sampling_strategy=strategy,  # samples only the minority class\n",
    "        random_state=0,  # for reproducibility\n",
    "        k_neighbors=5,\n",
    "        m_neighbors=10,\n",
    "        kind='borderline-1',\n",
    "        n_jobs=4\n",
    "    )  \n",
    "    \n",
    "    #separate train and test\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train_resampled, y_train_resampled = sm_b1.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "treated-thomson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:88, minority:12\n",
      "After run size majority:88, minority:88\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_borderline1_oversampling, df[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "protected-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_borderline2_oversampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    sm_b1 = BorderlineSMOTE(\n",
    "        sampling_strategy=strategy,  # samples only the minority class\n",
    "        random_state=0,  # for reproducibility\n",
    "        k_neighbors=5,\n",
    "        m_neighbors=10,\n",
    "        kind='borderline-2',\n",
    "        n_jobs=4\n",
    "    )  \n",
    "    \n",
    "    #separate train and test\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train_resampled, y_train_resampled = sm_b1.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "hollywood-omaha",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:88, minority:12\n",
      "After run size majority:88, minority:87\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_borderline2_oversampling, df[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-fairy",
   "metadata": {},
   "source": [
    "6. SVM SMOTE [notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-05-Oversampling/05-06-SVM-SMOTE.ipynb), [Document]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "beneficial-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svmsmote_oversampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    sm = SVMSMOTE(\n",
    "        sampling_strategy=strategy,  # samples only the minority class\n",
    "        random_state=0,              # for reproducibility\n",
    "        k_neighbors=5,\n",
    "        m_neighbors=10,\n",
    "        n_jobs=4,\n",
    "        svm_estimator = SVC(kernel='linear')\n",
    "    )  \n",
    "    \n",
    "    #separate train and test\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train_resampled, y_train_resampled = sm.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "russian-revision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:88, minority:12\n",
      "After run size majority:88, minority:57\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_svmsmote_oversampling, df[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-radiation",
   "metadata": {},
   "source": [
    "7. K-Means SMOTE [notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-05-Oversampling/05-07-K-Means-SMOTE.ipynb), [Document]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "engaged-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeanssmote_oversampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    sm = KMeansSMOTE(\n",
    "        sampling_strategy=strategy,  # samples only the minority class\n",
    "        random_state=0,              # for reproducibility\n",
    "        k_neighbors=2,\n",
    "        n_jobs=None,\n",
    "        kmeans_estimator=KMeans(n_clusters=3, random_state=0),\n",
    "        cluster_balance_threshold=0.1,\n",
    "        density_exponent='auto'\n",
    "    )  \n",
    "    \n",
    "    #separate train and test\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train_resampled, y_train_resampled = sm.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "embedded-checklist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:88, minority:12\n",
      "After run size majority:88, minority:89\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_kmeanssmote_oversampling, df[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-modification",
   "metadata": {},
   "source": [
    "#### COMBINATION OF UNDER AND OVER SAMPLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-environment",
   "metadata": {},
   "source": [
    "1. SMOTE + ENN [notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-06-Over-and-Undersampling/06-01-SMOTEENN-and-SMOTETomek.ipynb), [Document]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "after-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sm_enn_sampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    sm = SMOTE(\n",
    "        sampling_strategy=strategy,  # samples only the minority class\n",
    "        random_state=0,  # for reproducibility\n",
    "        k_neighbors=5,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    \n",
    "    # define under sampling strategy\n",
    "    # need ENN  as argument of SMOTEENN\n",
    "    enn = EditedNearestNeighbours(\n",
    "        sampling_strategy=strategy,\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=4)\n",
    "\n",
    "    smenn = SMOTEENN(\n",
    "        sampling_strategy='auto',  # samples only the minority class\n",
    "        random_state=0,  # for reproducibility\n",
    "        smote=sm,\n",
    "        enn=enn,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    \n",
    "    #separate train and test\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train_resampled, y_train_resampled = smenn.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "intended-equivalent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:88, minority:12\n",
      "After run size majority:88, minority:88\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_sm_enn_sampling, df[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-treaty",
   "metadata": {},
   "source": [
    "2. SMOTE + Tomek [notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-06-Over-and-Undersampling/06-01-SMOTEENN-and-SMOTETomek.ipynb), [Document]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "social-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sm_tomek_sampling(df, strategy='auto'):\n",
    "    \n",
    "    # define oversampling strategy\n",
    "    sm = SMOTE(\n",
    "        sampling_strategy=strategy,  # samples only the minority class\n",
    "        random_state=0,  # for reproducibility\n",
    "        k_neighbors=5,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    \n",
    "    # define under sampling strategy\n",
    "    # need tomek as argument of SMOTETomek\n",
    "    tl = TomekLinks(\n",
    "        sampling_strategy='all',\n",
    "        n_jobs=4)\n",
    "\n",
    "    smtomek = SMOTETomek(\n",
    "        sampling_strategy='auto',  # samples only the minority class\n",
    "        random_state=0,  # for reproducibility\n",
    "        smote=sm,\n",
    "        tomek=tl,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    \n",
    "    #separate train and test\n",
    "    x_train = df.drop(columns=[target])\n",
    "    y_train=df[target]\n",
    "    \n",
    "    # fit and apply the transform\n",
    "    x_train_resampled, y_train_resampled = smtomek.fit_resample(x_train, y_train)\n",
    "    \n",
    "    # merging y to x\n",
    "    x_train_resampled[target] = y_train_resampled\n",
    "    return x_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "blank-milton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before run size majority:88, minority:12\n",
      "After run size majority:88, minority:88\n"
     ]
    }
   ],
   "source": [
    "run_method(apply_sm_tomek_sampling, df[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-delay",
   "metadata": {},
   "source": [
    "#### ENSEMBLE IMBALANCED LEARNING TECHNIQUE\n",
    "* *TODO: imblearn comes with model + sampling techniques, review to move this to more appropriate place* as these techniques is different from just the data sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "historic-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just re-sampling methods (no classifier)\n",
    "\n",
    "resampling_dict = {\n",
    "    \n",
    "    'random': RandomUnderSampler(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        replacement=False,\n",
    "    ),\n",
    "\n",
    "    'smote': SMOTE(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        k_neighbors=5,\n",
    "        n_jobs=4,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "continuing-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble methods (with or without resampling)\n",
    "\n",
    "ensemble_dict = {\n",
    "\n",
    "    # balanced random forests (bagging)\n",
    "    'balancedRF': BalancedRandomForestClassifier(\n",
    "        n_estimators=20,\n",
    "        criterion='gini',\n",
    "        max_depth=3,\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=4,\n",
    "        random_state=2909,\n",
    "    ),\n",
    "\n",
    "    # bagging of Logistic regression, no resampling\n",
    "    'bagging': BaggingClassifier(\n",
    "        base_estimator=LogisticRegression(random_state=2909),\n",
    "        n_estimators=20,\n",
    "        n_jobs=4,\n",
    "        random_state=2909,\n",
    "    ),\n",
    "\n",
    "    # bagging of Logistic regression, with resampling\n",
    "    'balancedbagging': BalancedBaggingClassifier(\n",
    "        base_estimator=LogisticRegression(random_state=2909),\n",
    "        n_estimators=20,\n",
    "        max_samples=1.0,  # The number of samples to draw from X to train each base estimator\n",
    "        max_features=1.0,  # The number of features to draw from X to train each base estimator\n",
    "        bootstrap=True,\n",
    "        bootstrap_features=False,\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=4,\n",
    "        random_state=2909,\n",
    "    ),\n",
    "\n",
    "    # boosting + undersampling\n",
    "    'rusboost': RUSBoostClassifier(\n",
    "        base_estimator=None,\n",
    "        n_estimators=20,\n",
    "        learning_rate=1.0,\n",
    "        sampling_strategy='auto',\n",
    "        random_state=2909,\n",
    "    ),\n",
    "\n",
    "    # bagging + boosting + under-sammpling\n",
    "    'easyEnsemble': EasyEnsembleClassifier(\n",
    "        n_estimators=20,\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=4,\n",
    "        random_state=2909,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "front-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to train random forests and evaluate the peensembleormance\n",
    "\n",
    "# ensemble = ensemble_dict['choose_ensemble_technique']\n",
    "\n",
    "def run_ensemble(model_name, X_train, y_train):\n",
    "    print(\"{0}\".format(model_name), end=': ')\n",
    "\n",
    "    ensemble = ensemble_dict[model_name]\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    pred = ensemble.predict_proba(X_train)\n",
    "    \n",
    "    print(\"roc_auc: {0}\".format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    return roc_auc_score(y_train, pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "hearing-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balancedRF: roc_auc: 0.9743754609144544\n",
      "bagging: roc_auc: 0.959160674778761\n",
      "balancedbagging: roc_auc: 0.9609554756637169\n",
      "rusboost: roc_auc: 0.9831065634218289\n",
      "easyEnsemble: roc_auc: 0.9853774889380531\n"
     ]
    }
   ],
   "source": [
    "for model_name in ensemble_dict.keys():\n",
    "    run_ensemble(model_name, df.drop(columns=[target]), df[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-earthquake",
   "metadata": {},
   "source": [
    "#### Cost Sensitive learning approaches\n",
    "* **Misclassification cost as part of learning**\n",
    "    1. Defining the class_weight for those estimators that allow it, when we set the estimator. it can take values - |None|balanced|{0:1, and 1:10}(misclassification of class 1 will be penalized 10 times)|\n",
    "    2. Passing the sample_weight vector with the weights for every single observation, when we *fit the estimator*. Sample weight is the vector of the same length as y, containing the weight or penalty for each individual observation. It's more flexible as it allows us to set weight to the observation and not the classes.\n",
    "    NOTE: the costs such as 'class_weight' can be optimized using the hyperparameter optimization techniques.\n",
    "    \n",
    "* **MetaCost learning** - This is recent method and most likely has not been introduced in the popular libraries. Idea is to use the conditional risk of misclassifying the observations using Bayes Conditional Probabilities. For example refer [notebook](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-08-Cost-Sensitive-Learning/08-03-MetaCost.ipynb) and video in udemy course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-february",
   "metadata": {},
   "source": [
    "#### Probability Calibration\n",
    "* Refer slides [here](https://amueller.github.io/COMS4995-s20/slides/aml-10-calibration-imbalanced-data/#53) for understadning the topic\n",
    "* Refer [notebook](https://github.com/solegalli/machine-learning-imbalanced-data/tree/master/Section-09-Probability-Calibration) here for example for calibrated classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-poverty",
   "metadata": {},
   "source": [
    "### Save transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "genuine-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_balanced.head()\n",
    "# df_balanced.to_excel('../Bank_Personal_Loan_Modelling_balanced.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
